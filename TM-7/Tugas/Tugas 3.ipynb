{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools as it\n",
    "from sklearn import metrics\n",
    "from sklearn.base import clone\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import StratifiedKFold,cross_validate, train_test_split\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,mean_absolute_error,mean_squared_error,r2_score,make_scorer\n",
    "from abc import ABC, abstractmethod\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(y):\n",
    "  '''\n",
    "  Given a Pandas Series, it calculates the entropy.\n",
    "  y: variable with which calculate entropy.\n",
    "  '''\n",
    "  if isinstance(y, pd.Series):\n",
    "    a = y.value_counts()/y.shape[0]\n",
    "    entropy = np.sum(-a*np.log2(a+1e-9))\n",
    "    return(entropy)\n",
    "\n",
    "  else:\n",
    "    raise('Object must be a Pandas Series.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_impurity(y):\n",
    "  '''\n",
    "  Given a Pandas Series, it calculates the Gini Impurity.\n",
    "  y: variable with which calculate Gini Impurity.\n",
    "  '''\n",
    "  if isinstance(y, pd.Series):\n",
    "    p = y.value_counts()/y.shape[0]\n",
    "    gini = 1-np.sum(p**2)\n",
    "    return(gini)\n",
    "\n",
    "  else:\n",
    "    raise('Object must be a Pandas Series.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance(y):\n",
    "  '''\n",
    "  Function to help calculate the variance avoiding nan.\n",
    "  y: variable to calculate variance to. It should be a Pandas Series.\n",
    "  '''\n",
    "  if(len(y) == 1):\n",
    "    return 0\n",
    "  else:\n",
    "    return y.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain(y, mask, func=gini_impurity):\n",
    "  '''\n",
    "  It returns the Information Gain of a variable given a loss function.\n",
    "  y: target variable.\n",
    "  mask: split choice.\n",
    "  func: function to be used to calculate Information Gain in case os classification.\n",
    "  '''\n",
    "\n",
    "  a = sum(mask)\n",
    "  b = mask.shape[0] - a\n",
    "\n",
    "  if(a == 0 or b ==0):\n",
    "    ig = 0\n",
    "\n",
    "  else:\n",
    "    # if y.dtypes != 'O':\n",
    "    #   ig = variance(y) - (a/(a+b)* variance(y[mask])) - (b/(a+b)*variance(y[-mask]))\n",
    "    # else:\n",
    "    ig = func(y)-a/(a+b)*func(y[mask])-b/(a+b)*func(y[-mask])\n",
    "\n",
    "  return ig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_options(a):\n",
    "  '''\n",
    "  Creates all possible combinations from a Pandas Series.\n",
    "  a: Pandas Series from where to get all possible combinations.\n",
    "  '''\n",
    "  a = a.unique()\n",
    "\n",
    "  opt = []\n",
    "  for L in range(0, len(a)+1):\n",
    "      for subset in it.combinations(a, L):\n",
    "          subset = list(subset)\n",
    "          opt.append(subset)\n",
    "\n",
    "  return opt[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_information_gain_split(x, y, func=gini_impurity):\n",
    "  '''\n",
    "  Given a predictor & target variable, returns the best split, the error and the type of variable based on a selected cost function.\n",
    "  x: predictor variable as Pandas Series.\n",
    "  y: target variable as Pandas Series.\n",
    "  func: function to be used to calculate the best split.\n",
    "  '''\n",
    "\n",
    "  split_value = []\n",
    "  ig = []\n",
    "\n",
    "  numeric_variable = True if x.dtypes != 'O' else False\n",
    "\n",
    "  # Create options according to variable type\n",
    "  if numeric_variable:\n",
    "    options = x.sort_values().unique()[1:]\n",
    "  else:\n",
    "    options = categorical_options(x)\n",
    "\n",
    "  # Calculate ig for all values\n",
    "  for val in options:\n",
    "    mask =   x < val if numeric_variable else x.isin(val)\n",
    "    val_ig = information_gain(y, mask, func)\n",
    "    # Append results\n",
    "    ig.append(val_ig)\n",
    "    split_value.append(val)\n",
    "\n",
    "  # Check if there are more than 1 results if not, return False\n",
    "  if len(ig) == 0:\n",
    "    return(None,None,None, False)\n",
    "\n",
    "  else:\n",
    "  # Get results with highest IG\n",
    "    best_ig = max(ig)\n",
    "    best_ig_index = ig.index(best_ig)\n",
    "    best_split = split_value[best_ig_index]\n",
    "    return(best_ig,best_split,numeric_variable, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_split(y, data):\n",
    "  '''\n",
    "  Given a data, select the best split and return the variable, the value, the variable type and the information gain.\n",
    "  y: name of the target variable\n",
    "  data: dataframe where to find the best split.\n",
    "  '''\n",
    "  masks = data.drop(y, axis= 1).apply(max_information_gain_split, y = data[y])\n",
    "  if sum(masks.loc[3,:]) == 0:\n",
    "    return(None, None, None, None)\n",
    "\n",
    "  else:\n",
    "    # Get only masks that can be splitted\n",
    "    masks = masks.loc[:,masks.loc[3,:]]\n",
    "\n",
    "    # Get the results for split with highest IG\n",
    "    split_variable = masks.iloc[0].astype(np.float32).idxmax()\n",
    "    #split_valid = masks[split_variable][]\n",
    "    split_value = masks[split_variable][1]\n",
    "    split_ig = masks[split_variable][0]\n",
    "    split_numeric = masks[split_variable][2]\n",
    "\n",
    "    return(split_variable, split_value, split_ig, split_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_split(variable, value, data, is_numeric):\n",
    "  '''\n",
    "  Given a data and a split conditions, do the split.\n",
    "  variable: variable with which make the split.\n",
    "  value: value of the variable to make the split.\n",
    "  data: data to be splitted.\n",
    "  is_numeric: boolean considering if the variable to be splitted is numeric or not.\n",
    "  '''\n",
    "  if is_numeric:\n",
    "    data_1 = data[data[variable] < value]\n",
    "    data_2 = data[(data[variable] < value) == False]\n",
    "\n",
    "  else:\n",
    "    data_1 = data[data[variable].isin(value)]\n",
    "    data_2 = data[(data[variable].isin(value)) == False]\n",
    "\n",
    "  return(data_1,data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(data, target_factor):\n",
    "  '''\n",
    "  Given the target variable, make a prediction.\n",
    "  data: pandas series for target variable\n",
    "  target_factor: boolean considering if the variable is a factor or not\n",
    "  '''\n",
    "\n",
    "  # Make predictions\n",
    "  if target_factor:\n",
    "    pred = data.value_counts().idxmax()\n",
    "  else:\n",
    "    pred = data.mean()\n",
    "\n",
    "  return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tree(data,y, target_factor, max_depth = None,min_samples_split = None, min_information_gain = 1e-20, counter=0, max_categories = 20):\n",
    "  '''\n",
    "  Trains a Decission Tree\n",
    "  data: Data to be used to train the Decission Tree\n",
    "  y: target variable column name\n",
    "  target_factor: boolean to consider if target variable is factor or numeric.\n",
    "  max_depth: maximum depth to stop splitting.\n",
    "  min_samples_split: minimum number of observations to make a split.\n",
    "  min_information_gain: minimum ig gain to consider a split to be valid.\n",
    "  max_categories: maximum number of different values accepted for categorical values. High number of values will slow down learning process. R\n",
    "  '''\n",
    "\n",
    "  # Check that max_categories is fulfilled\n",
    "  if counter==0:\n",
    "    types = data.dtypes\n",
    "    check_columns = types[types == \"object\"].index\n",
    "    for column in check_columns:\n",
    "      var_length = len(data[column].value_counts())\n",
    "      if var_length > max_categories:\n",
    "        raise ValueError('The variable ' + column + ' has '+ str(var_length) + ' unique values, which is more than the accepted ones: ' +  str(max_categories))\n",
    "\n",
    "  # Check for depth conditions\n",
    "  if max_depth == None:\n",
    "    depth_cond = True\n",
    "\n",
    "  else:\n",
    "    if counter < max_depth:\n",
    "      depth_cond = True\n",
    "\n",
    "    else:\n",
    "      depth_cond = False\n",
    "\n",
    "  # Check for sample conditions\n",
    "  if min_samples_split == None:\n",
    "    sample_cond = True\n",
    "\n",
    "  else:\n",
    "    if data.shape[0] > min_samples_split:\n",
    "      sample_cond = True\n",
    "\n",
    "    else:\n",
    "      sample_cond = False\n",
    "\n",
    "  # Check for ig condition\n",
    "  if depth_cond & sample_cond:\n",
    "\n",
    "    var,val,ig,var_type = get_best_split(y, data)\n",
    "\n",
    "    # If ig condition is fulfilled, make split\n",
    "    if ig is not None and ig >= min_information_gain:\n",
    "\n",
    "      counter += 1\n",
    "\n",
    "      left,right = make_split(var, val, data,var_type)\n",
    "\n",
    "      # Instantiate sub-tree\n",
    "      split_type = \"<=\" if var_type else \"in\"\n",
    "      question =   \"{} {}  {}\".format(var,split_type,val)\n",
    "      # question = \"\\n\" + counter*\" \" + \"|->\" + var + \" \" + split_type + \" \" + str(val)\n",
    "      subtree = {question: []}\n",
    "\n",
    "      # Find answers (recursion)\n",
    "      yes_answer = train_tree(left,y, target_factor, max_depth,min_samples_split,min_information_gain, counter)\n",
    "\n",
    "      no_answer = train_tree(right,y, target_factor, max_depth,min_samples_split,min_information_gain, counter)\n",
    "\n",
    "      if yes_answer == no_answer:\n",
    "        subtree = yes_answer\n",
    "\n",
    "      else:\n",
    "        subtree[question].append(yes_answer)\n",
    "        subtree[question].append(no_answer)\n",
    "\n",
    "    # If it doesn't match IG condition, make prediction\n",
    "    else:\n",
    "      pred = make_prediction(data[y],target_factor)\n",
    "      return pred\n",
    "\n",
    "   # Drop dataset if doesn't match depth or sample conditions\n",
    "  else:\n",
    "    pred = make_prediction(data[y],target_factor)\n",
    "    return pred\n",
    "\n",
    "  return subtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_data(observation, arbol):\n",
    "  question = list(arbol.keys())[0]\n",
    "\n",
    "  if question.split()[1] == '<=':\n",
    "\n",
    "    if observation[question.split()[0]] <= float(question.split()[2]):\n",
    "      answer = arbol[question][0]\n",
    "    else:\n",
    "      answer = arbol[question][1]\n",
    "\n",
    "  else:\n",
    "\n",
    "    if observation[question.split()[0]] in (question.split()[2]):\n",
    "      answer = arbol[question][0]\n",
    "    else:\n",
    "      answer = arbol[question][1]\n",
    "\n",
    "  # If the answer is not a dictionary\n",
    "  if not isinstance(answer, dict):\n",
    "    return answer\n",
    "  else:\n",
    "    residual_tree = answer\n",
    "    return classifier_data(observation, answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
      "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
      "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
      "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
      "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
      "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
      "..       ...         ...   ...                ...        ...            ...   \n",
      "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
      "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
      "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
      "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
      "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
      "\n",
      "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
      "0          3.06                  0.28             2.29             5.64  1.04   \n",
      "1          2.76                  0.26             1.28             4.38  1.05   \n",
      "2          3.24                  0.30             2.81             5.68  1.03   \n",
      "3          3.49                  0.24             2.18             7.80  0.86   \n",
      "4          2.69                  0.39             1.82             4.32  1.04   \n",
      "..          ...                   ...              ...              ...   ...   \n",
      "173        0.61                  0.52             1.06             7.70  0.64   \n",
      "174        0.75                  0.43             1.41             7.30  0.70   \n",
      "175        0.69                  0.43             1.35            10.20  0.59   \n",
      "176        0.68                  0.53             1.46             9.30  0.60   \n",
      "177        0.76                  0.56             1.35             9.20  0.61   \n",
      "\n",
      "     od280/od315_of_diluted_wines  proline   target  \n",
      "0                            3.92   1065.0  class_0  \n",
      "1                            3.40   1050.0  class_0  \n",
      "2                            3.17   1185.0  class_0  \n",
      "3                            3.45   1480.0  class_0  \n",
      "4                            2.93    735.0  class_0  \n",
      "..                            ...      ...      ...  \n",
      "173                          1.74    740.0  class_2  \n",
      "174                          1.56    750.0  class_2  \n",
      "175                          1.56    835.0  class_2  \n",
      "176                          1.62    840.0  class_2  \n",
      "177                          1.60    560.0  class_2  \n",
      "\n",
      "[178 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "#load the wine dataset\n",
    "data = load_wine()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target_names[data.target]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'proline <=  760.0': [{'od280/od315_of_diluted_wines <=  2.12': [{'hue <=  0.96': [{'flavanoids <=  1.59': ['class_2',\n",
       "        'class_1']},\n",
       "      'class_1']},\n",
       "    {'flavanoids <=  0.99': ['class_2', 'class_1']}]},\n",
       "  {'flavanoids <=  2.19': ['class_2',\n",
       "    {'magnesium <=  139.0': ['class_0', 'class_1']}]}]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_depth = 5\n",
    "min_samples_split = 20\n",
    "min_information_gain  = 1e-5\n",
    "\n",
    "decision = train_tree(df,'target',True, max_depth,min_samples_split,min_information_gain)\n",
    "decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:  ['class_0', 'class_0', 'class_0', 'class_0', 'class_1', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_2', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_1', 'class_0', 'class_0', 'class_0', 'class_1', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_2', 'class_1', 'class_1', 'class_0', 'class_2', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_2', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_2', 'class_1', 'class_1', 'class_1', 'class_2', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_2', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_2', 'class_2', 'class_2', 'class_2', 'class_2', 'class_2', 'class_2', 'class_2', 'class_2', 'class_2', 'class_2', 'class_2', 'class_2', 'class_2', 'class_2', 'class_2', 'class_2', 'class_2', 'class_2', 'class_2', 'class_2', 'class_2', 'class_2', 'class_2', 'class_2', 'class_2', 'class_2', 'class_2', 'class_2', 'class_2', 'class_2', 'class_2', 'class_2', 'class_2', 'class_2', 'class_2', 'class_2', 'class_2', 'class_2', 'class_2', 'class_2', 'class_2', 'class_2', 'class_2', 'class_2', 'class_2', 'class_2', 'class_2'] \n",
      "\n",
      "Real values: ['class_0' 'class_0' 'class_0' 'class_0' 'class_0' 'class_0' 'class_0'\n",
      " 'class_0' 'class_0' 'class_0' 'class_0' 'class_0' 'class_0' 'class_0'\n",
      " 'class_0' 'class_0' 'class_0' 'class_0' 'class_0' 'class_0' 'class_0'\n",
      " 'class_0' 'class_0' 'class_0' 'class_0' 'class_0' 'class_0' 'class_0'\n",
      " 'class_0' 'class_0' 'class_0' 'class_0' 'class_0' 'class_0' 'class_0'\n",
      " 'class_0' 'class_0' 'class_0' 'class_0' 'class_0' 'class_0' 'class_0'\n",
      " 'class_0' 'class_0' 'class_0' 'class_0' 'class_0' 'class_0' 'class_0'\n",
      " 'class_0' 'class_0' 'class_0' 'class_0' 'class_0' 'class_0' 'class_0'\n",
      " 'class_0' 'class_0' 'class_0' 'class_1' 'class_1' 'class_1' 'class_1'\n",
      " 'class_1' 'class_1' 'class_1' 'class_1' 'class_1' 'class_1' 'class_1'\n",
      " 'class_1' 'class_1' 'class_1' 'class_1' 'class_1' 'class_1' 'class_1'\n",
      " 'class_1' 'class_1' 'class_1' 'class_1' 'class_1' 'class_1' 'class_1'\n",
      " 'class_1' 'class_1' 'class_1' 'class_1' 'class_1' 'class_1' 'class_1'\n",
      " 'class_1' 'class_1' 'class_1' 'class_1' 'class_1' 'class_1' 'class_1'\n",
      " 'class_1' 'class_1' 'class_1' 'class_1' 'class_1' 'class_1' 'class_1'\n",
      " 'class_1' 'class_1' 'class_1' 'class_1' 'class_1' 'class_1' 'class_1'\n",
      " 'class_1' 'class_1' 'class_1' 'class_1' 'class_1' 'class_1' 'class_1'\n",
      " 'class_1' 'class_1' 'class_1' 'class_1' 'class_1' 'class_1' 'class_1'\n",
      " 'class_1' 'class_1' 'class_1' 'class_1' 'class_2' 'class_2' 'class_2'\n",
      " 'class_2' 'class_2' 'class_2' 'class_2' 'class_2' 'class_2' 'class_2'\n",
      " 'class_2' 'class_2' 'class_2' 'class_2' 'class_2' 'class_2' 'class_2'\n",
      " 'class_2' 'class_2' 'class_2' 'class_2' 'class_2' 'class_2' 'class_2'\n",
      " 'class_2' 'class_2' 'class_2' 'class_2' 'class_2' 'class_2' 'class_2'\n",
      " 'class_2' 'class_2' 'class_2' 'class_2' 'class_2' 'class_2' 'class_2'\n",
      " 'class_2' 'class_2' 'class_2' 'class_2' 'class_2' 'class_2' 'class_2'\n",
      " 'class_2' 'class_2' 'class_2']\n"
     ]
    }
   ],
   "source": [
    "#Prediction\n",
    "obese_prediction = []\n",
    "num_obs = 178\n",
    "\n",
    "for i in range(num_obs):\n",
    "  obs_pred = classifier_data(df.iloc[i,:], decision)\n",
    "  obese_prediction.append(obs_pred)\n",
    "\n",
    "print(\"Predictions: \",obese_prediction,\n",
    "\"\\n\\nReal values:\", df.target.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the confusion matrix\n",
    "observation = df.target.to_numpy()\n",
    "answer = obese_prediction\n",
    "# answer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.94\n",
      "Precision : 0.94\n",
      "Recall : 0.94\n"
     ]
    }
   ],
   "source": [
    "Accuracy = metrics.accuracy_score(observation, answer)\n",
    "# Menghitung Presisi\n",
    "Precision = metrics.precision_score(observation, answer, average = 'micro', zero_division= 1)\n",
    "# Menghitung Sensitivitas\n",
    "Recall = metrics.recall_score(observation, answer, average = 'micro', zero_division= 1)\n",
    "\n",
    "print(f'Accuracy : {Accuracy:.2f}')\n",
    "print(f'Precision : {Precision:.2f}')\n",
    "print(f'Recall : {Recall:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
