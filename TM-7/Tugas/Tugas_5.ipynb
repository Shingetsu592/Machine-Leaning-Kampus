{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools as it\n",
    "from sklearn import metrics\n",
    "from sklearn.base import clone\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import StratifiedKFold,cross_validate, train_test_split\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,mean_absolute_error,mean_squared_error,r2_score,make_scorer\n",
    "from abc import ABC, abstractmethod\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
      "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
      "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
      "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
      "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
      "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
      "..       ...         ...   ...                ...        ...            ...   \n",
      "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
      "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
      "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
      "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
      "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
      "\n",
      "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
      "0          3.06                  0.28             2.29             5.64  1.04   \n",
      "1          2.76                  0.26             1.28             4.38  1.05   \n",
      "2          3.24                  0.30             2.81             5.68  1.03   \n",
      "3          3.49                  0.24             2.18             7.80  0.86   \n",
      "4          2.69                  0.39             1.82             4.32  1.04   \n",
      "..          ...                   ...              ...              ...   ...   \n",
      "173        0.61                  0.52             1.06             7.70  0.64   \n",
      "174        0.75                  0.43             1.41             7.30  0.70   \n",
      "175        0.69                  0.43             1.35            10.20  0.59   \n",
      "176        0.68                  0.53             1.46             9.30  0.60   \n",
      "177        0.76                  0.56             1.35             9.20  0.61   \n",
      "\n",
      "     od280/od315_of_diluted_wines  proline   target  \n",
      "0                            3.92   1065.0  class_0  \n",
      "1                            3.40   1050.0  class_0  \n",
      "2                            3.17   1185.0  class_0  \n",
      "3                            3.45   1480.0  class_0  \n",
      "4                            2.93    735.0  class_0  \n",
      "..                            ...      ...      ...  \n",
      "173                          1.74    740.0  class_2  \n",
      "174                          1.56    750.0  class_2  \n",
      "175                          1.56    835.0  class_2  \n",
      "176                          1.62    840.0  class_2  \n",
      "177                          1.60    560.0  class_2  \n",
      "\n",
      "[178 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "#Load Data\n",
    "data = load_wine()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target_names[data.target]\n",
    "print(df)\n",
    "\n",
    "#Train Test Split\n",
    "train = df.sample(frac = 0.7, random_state = 40)\n",
    "test = df.drop(train.index)\n",
    "\n",
    "y_train = train[\"target\"]\n",
    "x_train = train.drop(\"target\", axis = 1)\n",
    "\n",
    "y_test = test[\"target\"]\n",
    "x_test = test.drop(\"target\", axis = 1)\n",
    "\n",
    "#Training â€“ Count Posterior\n",
    "means = train.groupby([\"target\"]).mean() # Find mean of each class\n",
    "var = train.groupby([\"target\"]).var() # Find variance of each class\n",
    "prior = (train.groupby(\"target\").count() / len(train)).iloc[:,1] # Find prior probability of each class\n",
    "classes = np.unique(train[\"target\"].tolist()) # Storing all possible classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification\n",
    "def Normal(n, mu, var):\n",
    "    # Function to return pdf of Normal(mu, var) evaluated at x\n",
    "    sd = np.sqrt(var)\n",
    "    pdf = (np.e ** (-0.5 * ((n - mu)/sd) ** 2)) / (sd * np.sqrt(2 * np.pi))\n",
    "    return pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict(X):\n",
    "    Predictions = []\n",
    "    \n",
    "    for i in X.index: # Loop through each instances\n",
    "        ClassLikelihood = []\n",
    "        instance = X.loc[i]\n",
    "        for cls in classes: # Loop through each class\n",
    "            FeatureLikelihoods = []\n",
    "            FeatureLikelihoods.append(np.log(prior[cls])) # Append log prior of class 'cls'\n",
    "            for col in x_train.columns: # Loop through each feature\n",
    "                data = instance[col]\n",
    "                mean = means[col].loc[cls] # Find the mean of column 'col' that are in class 'cls'\n",
    "                variance = var[col].loc[cls] # Find the variance of column 'col' that are in class 'cls'\n",
    "                Likelihood = Normal(data, mean, variance)\n",
    "                if Likelihood != 0:\n",
    "                    Likelihood = np.log(Likelihood) # Find the log-likelihood evaluated at x\n",
    "                else:\n",
    "                    Likelihood = 1/len(train) \n",
    "                \n",
    "                FeatureLikelihoods.append(Likelihood)\n",
    "                \n",
    "            TotalLikelihood = sum(FeatureLikelihoods) # Calculate posterior\n",
    "            ClassLikelihood.append(TotalLikelihood)\n",
    "            \n",
    "        MaxIndex = ClassLikelihood.index(max(ClassLikelihood)) # Find largest posterior position\n",
    "        Prediction = classes[MaxIndex]\n",
    "        Predictions.append(Prediction)     \n",
    "    return Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Accuracy(y, prediction):\n",
    "    # Function to calculate accuracy\n",
    "    y = list(y)\n",
    "    prediction = list(prediction)\n",
    "    score = 0\n",
    "    for i, j in zip(y, prediction):\n",
    "        if i == j:\n",
    "            score += 1   \n",
    "    return score / len(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9920\n",
      "Testing Accuracy: 0.9434\n"
     ]
    }
   ],
   "source": [
    "PredictTrain = Predict(x_train)\n",
    "PredictTest = Predict(x_test)\n",
    "\n",
    "print('Training Accuracy: %.4f' % round(Accuracy(y_train, PredictTrain), 5))\n",
    "print('Testing Accuracy: %.4f' % round(Accuracy(y_test, PredictTest), 5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9920\n",
      "Testing Accuracy: 0.9434\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(x_train, y_train)\n",
    "SkTrain = clf.predict(x_train) # Predicting on the train set\n",
    "SkTest = clf.predict(x_test) # Predicting on the test set\n",
    "\n",
    "print('Training Accuracy: %.4f' % round(Accuracy(y_train, SkTrain), 5))\n",
    "print('Testing Accuracy: %.4f' % round(Accuracy(y_test, SkTest), 5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
